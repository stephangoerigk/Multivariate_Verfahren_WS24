[["cross.html", "Kapitel 3 Konfirmatorische Faktorenanalyse 3.1 Grundlegendes 3.2 Beispiel zur Anwendung der CFA", " Kapitel 3 Konfirmatorische Faktorenanalyse Die konfirmatorische Faktorenanalyse (engl. Confirmatory Factor Analysis, CFA) ist eine hypothesenprüfende statistische Methode, die verwendet wird, um zu überprüfen, ob die Daten zu einem vorab definierten Modell passen. Im Gegensatz zur explorativen Faktorenanalyse, bei der die Faktorenstruktur aus den Daten extrahiert wird, testet die CFA spezifische theoretische Modelle, die die Zuordnung von Variablen (Indikatoren) zu latenten Konstrukten vorschreiben. Die CFA ermöglicht es, die Konstruktvalidität von Messinstrumenten zu bewerten, indem sie überprüft, ob die beobachteten Daten mit der postulierten Struktur übereinstimmen. Zwei “Unterfamilien” faktorenanalytischer Methoden Konfirmatorische Faktorenanalyse (CFA): Eine hypothesenprüfende Methode, bei der ein vorab festgelegtes Modell getestet wird, das die Zuordnung von Indikatoren zu latenten Variablen definiert. Ziel der CFA ist es, die Passung des Modells zu den beobachteten Daten zu überprüfen. Explorative Faktorenanalyse (EFA): Eine hypothesengenerierende Methode, die verwendet wird, wenn die Zuordnung der Indikatoren zu den latenten Variablen noch unbekannt ist. Ziel der EFA ist es, verborgene Faktorenstrukturen in den Daten zu entdecken. Beide Methoden zielen darauf ab, wechselseitig unabhängige Faktoren zu identifizieren, die die Zusammenhänge zwischen den Variablen erklären. 3.1 Grundlegendes Theoretisch fundierte Modellbildung: Bei der CFA wird das Modell basierend auf theoretischen Überlegungen und vorheriger Forschung spezifiziert. Die Zuordnung der Indikatoren zu den latenten Faktoren wird also vorab festgelegt. Fit-Indizes zur Modellbewertung: Die Passung des Modells zu den beobachteten Daten wird anhand von Fit-Indizes bewertet, z.B. dem Root Mean Square Error of Approximation (RMSEA), dem Standardized Root Mean Square Residual (SRMR) oder dem Comparative Fit Index (CFI). Diese Indizes geben an, wie gut das Modell zu den Daten passt. Implikationen der Faktorenanalyse Latente Variablen als Ursache für beobachtete Zusammenhänge: Die CFA geht davon aus, dass die Korrelationen zwischen den manifesten Variablen auf die zugrunde liegenden latenten Faktoren zurückzuführen sind, die durch die CFA modelliert werden. Modellanpassung: Ein gut passendes CFA-Modell sollte eine hohe Übereinstimmung zwischen den vorhergesagten und den beobachteten Kovarianzen der manifesten Variablen zeigen. Ist dies nicht der Fall, müssen entweder das Modell oder die Messinstrumente überarbeitet werden. 3.2 Beispiel zur Anwendung der CFA Um die Anwendung der CFA zu verdeutlichen, folgt ein Beispiel mit Daten zu kognitiven Fähigkeiten. In diesem Beispiel soll überprüft werden, ob die Zusammenhänge zwischen vier kognitiven Tests durch einen zugrunde liegenden g-Faktor (allgemeine Intelligenz) erklärt werden können. Die vier kognitiven Tests sind: - Arithmetische Kompetenz (Variablenname: MathComp) - Figural-induktives Denken (Variablenname: FigReas) - Wortbedeutung (Variablenname: WordMean) - Langzeitgedächtnis (Variablenname: LongMem) Die Stichprobe umfasst N=196 Personen (48% Frauen; 52% Männer) im Alter von 16 bis 63 Jahren (M=37.79; SD=11.89). 3.2.1 Fragestellung Lassen sich die Zusammenhänge zwischen den vorliegenden vier kognitiven Tests durch einen g-Faktor erklären? 3.2.2 Begründung der Auswertemethode Da bereits eine gerichtete Hypothese über die Faktorenstruktur vorliegt, die zudem durch die Literatur gut begründet ist, wird die konfirmatorische Faktorenanalyse (CFA) zur Überprüfung der Fragestellung herangezogen. Die CFA testet, ob die vier kognitiven Tests durch einen gemeinsamen g-Faktor erklärt werden können. Der Datensatz wurde unter der Bezeichnung “GScreen” eingelesen. 3.2.3 Setup # install.packages(&quot;lavaan&quot;) library(lavaan) # install.packages(&quot;semPlot&quot;) library(semPlot) 3.2.4 Prüfung der Anwendungsvoraussetzungen Bevor die CFA durchgeführt wird, sollten die Daten auf ihre Eignung geprüft werden. Zu den wichtigsten Voraussetzungen zählen: Korrelation zwischen den Variablen: Die Indikatoren sollten ausreichend miteinander korrelieren, damit sie durch einen gemeinsamen latenten Faktor erklärt werden können. Allerdings sollten die Korrelationen nicht so stark sein, dass Multikollinearität vorliegt. Stichprobengröße: Für die CFA ist die Stichprobengröße entscheidend. Schönbrodt und Perugini (2013) argumentieren, dass Korrelationen bei einer Stichprobengröße von etwa 250 Personen stabil sind, was eine solide Grundlage für die Interpretation der CFA-Ergebnisse bietet. Univariate Normalverteilung: Die CFA setzt voraus, dass die beobachteten Variablen normalverteilt sind, zumindest bei größeren Stichproben, um valide Ergebnisse zu gewährleisten. Darüber hinaus sollten folgende Punkte berücksichtigt werden: Multikollinearität: Zu starke Korrelationen zwischen den Indikatoren (Multikollinearität) können zu Problemen führen. Die Determinante der Korrelationsmatrix bietet eine Möglichkeit, dies zu überprüfen. Eine Determinante nahe 0 deutet auf problematische Multikollinearität hin. Modellidentifizierbarkeit: Ein Modell muss hinreichend identifiziert sein, d.h., es müssen genügend Datenpunkte vorhanden sein, um die Modellparameter schätzen zu können. # Korrelation der Variablen prüfen cor_matrix_CFA = cor(GScreen) det(cor_matrix_CFA) # Determinante der Korrelationsmatrix ## [1] 0.7009416 # Prüfen der Normalverteilung (z.B. mit Shapiro-Wilk-Test für jede Variable) apply(GScreen, 2, shapiro.test) ## $MathComp ## ## Shapiro-Wilk normality test ## ## data: newX[, i] ## W = 0.99508, p-value = 0.7616 ## ## ## $FigReas ## ## Shapiro-Wilk normality test ## ## data: newX[, i] ## W = 0.99144, p-value = 0.2871 ## ## ## $WordMean ## ## Shapiro-Wilk normality test ## ## data: newX[, i] ## W = 0.95918, p-value = 0.00001613 ## ## ## $LongMem ## ## Shapiro-Wilk normality test ## ## data: newX[, i] ## W = 0.99341, p-value = 0.5154 Die Ergebnisse zeigen, dass die Daten für die CFA geeignet sind. Die Korrelationen zwischen den Variablen sind ausreichend hoch, um eine gemeinsame Faktorenstruktur zu modellieren, was durch die Determinante der Korrelationsmatrix (0.70) bestätigt wird. Diese liegt weit über dem kritischen Wert nahe 0, was darauf hinweist, dass keine problematische Multikollinearität vorliegt. Die Ergebnisse des Shapiro-Wilk-Tests zur Überprüfung der Normalverteilung zeigen, dass die meisten Variablen (MathComp, FigReas und LongMem) keine signifikanten Abweichungen von der Normalverteilung aufweisen (p-Werte &gt; .05). Allerdings zeigt die Variable WordMean eine signifikante Abweichung von der Normalverteilung (p &lt; .05). Da die Stichprobengröße jedoch groß genug ist (N=200), kann diese Abweichung als tolerierbar angesehen werden. Insgesamt sind die Voraussetzungen für die Durchführung der CFA erfüllt. 3.2.4.1 Fit-Indizes Zu den wichtigsten Fit-Indizes gehören: Chi-Quadrat-Test: Testet die Abweichung zwischen dem Modell und den Daten. Ein nicht-signifikanter p-Wert deutet darauf hin, dass das Modell gut passt. RMSEA (Root Mean Square Error of Approximation): Ein RMSEA-Wert &lt; 0.06 gilt als guter Fit. CFI (Comparative Fit Index): Werte &gt; 0.95 gelten als Hinweis auf eine gute Modellpassung. SRMR (Standardized Root Mean Square Residual): Ein Wert &lt; 0.08 wird als akzeptabel angesehen. 3.2.4.2 Modellschätzung Das Modell wird in R mit der lavaan-Funktion cfa() geschätzt. model &lt;- &#39;GFactor =~ MathComp + FigReas + WordMean + LongMem&#39; fit &lt;- cfa(model, data = GScreen) summary(fit, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE) ## lavaan 0.6-18 ended normally after 30 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 8 ## ## Number of observations 200 ## ## Model Test User Model: ## ## Test statistic 3.254 ## Degrees of freedom 2 ## P-value (Chi-square) 0.196 ## ## Model Test Baseline Model: ## ## Test statistic 71.066 ## Degrees of freedom 6 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.981 ## Tucker-Lewis Index (TLI) 0.942 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -1165.605 ## Loglikelihood unrestricted model (H1) -1163.978 ## ## Akaike (AIC) 2347.210 ## Bayesian (BIC) 2373.596 ## Sample-size adjusted Bayesian (SABIC) 2348.251 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.056 ## 90 Percent confidence interval - lower 0.000 ## 90 Percent confidence interval - upper 0.162 ## P-value H_0: RMSEA &lt;= 0.050 0.348 ## P-value H_0: RMSEA &gt;= 0.080 0.455 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.030 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## GFactor =~ ## MathComp 1.000 0.473 0.399 ## FigReas 1.381 0.386 3.580 0.000 0.653 0.642 ## WordMean 1.184 0.336 3.523 0.000 0.560 0.504 ## LongMem 1.071 0.306 3.500 0.000 0.507 0.494 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .MathComp 1.185 0.136 8.724 0.000 1.185 0.841 ## .FigReas 0.609 0.117 5.192 0.000 0.609 0.588 ## .WordMean 0.924 0.122 7.597 0.000 0.924 0.746 ## .LongMem 0.797 0.103 7.735 0.000 0.797 0.756 ## GFactor 0.224 0.101 2.214 0.027 1.000 1.000 ## ## R-Square: ## Estimate ## MathComp 0.159 ## FigReas 0.412 ## WordMean 0.254 ## LongMem 0.244 3.2.5 Interpretation der SEM-Ergebnisse 3.2.5.1 Modell-Fit Der Chi-Quadrat-Wert ist nicht signifikant (χ²(2) = 3.254, p = .196), was darauf hinweist, dass das Modell die Daten gut repräsentiert. Ein nicht-signifikanter p-Wert bedeutet, dass das Modell die beobachteten Daten nicht signifikant von der theoretischen Struktur abweicht (Nullhypothese des Tests: Es gibt keinen Unterschied zwischen dem theoretischen Modell und den beobachteten Daten, daher ist ein n.s. Ergebnis hier erwünscht). Die Fit-Indizes bestätigen die Angemessenheit des Modells: Root Mean Square Error of Approximation (RMSEA): Der RMSEA-Wert beträgt 0.056, was auf eine akzeptable Modellpassung hinweist. Werte unter 0.06 gelten als sehr gut, während Werte zwischen 0.05 und 0.08 als akzeptabel angesehen werden. Das 90%-Konfidenzintervall (0.000 bis 0.162) zeigt, dass der RMSEA im akzeptablen Bereich liegt. Standardized Root Mean Square Residual (SRMR): Der SRMR-Wert beträgt 0.030, was deutlich unter der kritischen Schwelle von 0.08 liegt und auf eine sehr gute Modellpassung hinweist. Der SRMR misst die Differenz zwischen den beobachteten und modellbasierten Korrelationen und zeigt, dass das Modell die beobachteten Korrelationen gut abbildet. Comparative Fit Index (CFI): Der CFI-Wert beträgt 0.981, was auf eine sehr gute Modellpassung hinweist (Werte über 0.95 gelten als exzellent). 3.2.5.2 Parameter-Interpretation Die Parameter des Modells sind durchweg signifikant, was darauf hindeutet, dass die Beziehungen zwischen den latenten Variablen und ihren Indikatoren gut modelliert sind: Latente Variablen und ihre Indikatoren: Die latente Variable GFactor wird signifikant durch alle Indikatoren gemessen: MathComp: Die standardisierte Ladung beträgt 0.399, was bedeutet, dass etwa 40% der Varianz von MathComp durch den g-Faktor erklärt werden. FigReas: Mit einer Ladung von 0.642 zeigt FigReas die höchste Korrelation mit dem g-Faktor. WordMean: Die Ladung von 0.504 zeigt eine moderate Korrelation mit dem g-Faktor. LongMem: LongMem hat ebenfalls eine signifikante Ladung von 0.494. 3.2.5.3 Regressionsbeziehungen Alle Pfade zwischen der latenten Variable (GFactor) und den Indikatoren sind signifikant (p &lt; .001), was darauf hinweist, dass die kognitiven Tests gut durch den g-Faktor erklärt werden. Die stärkste Beziehung besteht zwischen dem g-Faktor und FigReas (\\(\\beta\\) = 0.642), was bedeutet, dass FigReas am stärksten durch den g-Faktor beeinflusst wird. MathComp hat die niedrigste Faktorladung (\\(\\beta\\) = 0.399), aber auch hier wird die Beziehung durch den g-Faktor signifikant erklärt. 3.2.5.4 Erklärte Varianz Die R-Quadrat-Werte geben Auskunft darüber, wie gut die Indikatoren durch die latente Variable (GFactor) erklärt werden: - MathComp: 15.9% der Varianz von MathComp wird durch den g-Faktor erklärt. - FigReas: 41.2% der Varianz wird durch den g-Faktor erklärt, was eine starke Erklärungsleistung zeigt. - WordMean: 25.4% der Varianz wird durch den g-Faktor erklärt. - LongMem: 24.4% der Varianz wird durch den g-Faktor erklärt. Diese Ergebnisse zeigen, dass der g-Faktor einen substanziellen Anteil der Varianz in den kognitiven Tests erklärt, insbesondere bei FigReas, was die Bedeutung dieses Tests für die Messung der allgemeinen Intelligenz unterstreicht. 3.2.6 Grafische Darstellung des Modells Die grafische Darstellung eines CFA-Modells ermöglicht es, die Beziehungen zwischen den latenten Variablen und ihren Indikatoren sowie die Regressionspfade visuell zu erfassen. Das semPlot-Paket kann verwendet werden, um das Modell übersichtlich darzustellen. Dabei werden die standardisierten Ladungen, die Korrelationen zwischen den Variablen sowie die Residuen abgebildet. semPaths(fit, &quot;std&quot;, layout = &quot;tree&quot;, residuals = TRUE, whatLabels = &quot;std&quot;, intercepts = FALSE) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
